---
title: "README"
author: "treepruner"
date: "August 23, 2015"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---
title: "# Project README"
author: "treepruner"
date: "August 22, 2015"
output:
  html_document:
    keep_md: yes
---


# Project Description 
Getting and Cleaning Data course project takes files from
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 
and produces a tidy data by subject and activity of any original measurement fields 
with "mean" or "std" in their name.


##Project design and data processing
I first read the README and features_info.txt to get an overview of the data. Next I looked at the files in a text editor. The text editor wasn't helpful since you can't tell where one field stops and another starts.

Here are the row counts for the test data sets:

| file                |contents                            | rows count| column count|
|---------------------|------------------------------------|-----------|-------------|
| X_test.txt          | Test set data                      |  2947     |561|
| y_test.txt          | Test set column labels             |  2947     | 1 |
| subject_test.txt    | Test set subject row labels        |  2947     | 1 |
| features.txt        | Test and Train column descriptions |  561      | 2 |
| activity_labels.txt | Activity codes and labels          |  6        | 2 |
| X_train.txt         | Train set data                     |  7352     |561|
| y_train.txt         | Train set column labels            |  7352     | 1 |
| subject_train.txt   | Train set subject row labels       |  7352     | 1 |


The files are broken apart very strangely. 

The number of columns in X_test.txt matches the # rows in features.txt. I was able to confirm that features.txt contains the column headings for X_test.txt.

The number of rows in subject_test.txt and y_test.txt match the # of rows in X_test.txt. I was able to confirm that these files have the subject and activity test information for each row in x_test.txt

The codes in the rows of x_test.txt match the codes in activity_labels.txt

The training datasets work in a similar fashion.


## Manipulation of the study data

### Step 0 - Download, Unzip and Read in files
- files downloaded from "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip" 
- initial read is given a suffix of 0
- suffix is incremented by 1 for each transformation 


#### read in activity, features 
- activity_labels.txt imported as as activity_cd and activity
- features.txt imported as feature_cd and feature

##### Clean features file. Features contains the column labels for the test and training datasets, but there are non-alphanumeric symbols and duplicate entries. 
- convert "-"  and "," to "_"
- remove  "("  and ")"
- make unique by adding suffix of left 0 padded row numbers, e.g., _001, _002 and so on. These were stripped out later.

#### read in testing data, check rows, add existing labels
- initial file read in with suffix of 0 and all lower case
- each alteration increments the suffix
- update column names
- add subject and test columns to left side with cbind


#### read in training data, add existing labels
- initial file read in with suffix of 0 and all lower case
- each alteration increments the suffix
- update column names
- add subject and test columns to left side with cbind


### Step 1 - Merge training and test sets 
Combine testing and training rows into new data frame with rbind.


### Step 2 - Extract only the measurements on the mean and standard deviation 
I was unable to combine in a single step... matches seemed to override exclusions, so these were done on multiple steps

- take any fields containing any case of "mean" or "std"
- remove columns related to the angle variable
- remove columns related to the meanFreq, which is a summary measure


### Step 3 - Use descriptive activity names on activities in the data set 
- add activity label to left side with merge
- leave in the activity_cd on purpose


### Step 4 -  Label the data set with descriptive variable names                  
- save current column names
- alter to remove the _### required for uniqueness by position
- fix the 3 without _### that got wrecked
- replace the column names
- check column names are still unique

### Step 5 - Create a tidy data set with average of each variable for each activity and subject
- use dplyr's "arrange" and "group_by" with "summarise_each" to create a dataset with one row per subject and activity. Note that the US spelling of summarize_each failed to run.
- save out with a "|" for the delimiter so the fields can be told apart in a text editor


## Code to read it back in & set column classes
temp <-read.table("tidy.txt"
       , sep = "|"
       , header = TRUE
       , colClasses = c("integer", "factor", "numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric","numeric","numeric","numeric"
                                   ,"numeric","numeric","numeric" )
)  



## Sources
- http://stackoverflow.com/questions/7963898/extracting-the-last-n-characters-from-a-string-in-r
- https://fishr.wordpress.com/2014/04/17/dplyr-example-1/
- https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf
- https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf
